{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook I : Calibration with planes\n",
    "\n",
    "The answer to each question is written below the code Cell concerned. For a Cell i and a question n,the answer will be in this format :<br> \n",
    "### Question n\n",
    "This is the answer to the question n on the Cell i. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Calibraton with OpenCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# This is a value for the termination criterion of the subpixel corner localizer\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the 3D point coordinates and loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you have 3D points for the checkerboard (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "# Here you load the image files\n",
    "images = glob.glob('left/left*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "print(len(images))\n",
    "counter = 0\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6),None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        counter+=1\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        img = cv2.drawChessboardCorners(img, (7,6), corners2,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "In the Cell 1, we ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtx ==  [[534.07088364   0.         341.53407553]\n",
      " [  0.         534.11914595 232.9456526 ]\n",
      " [  0.           0.           1.        ]]\n",
      "det rotation_0 = 1.0000000000000004\n",
      "[[-4.20818148e+02 -6.11700780e+01  4.70156932e+02  7.10303538e+03]\n",
      " [ 4.45519202e+01 -5.64957870e+02  1.35590083e+02  3.94155712e+03]\n",
      " [ 2.71751068e-01 -1.63273781e-01  9.48416063e-01  1.48593055e+01]]\n",
      "det rotation_1 = 0.9999999999999999\n",
      "[[ 1.23637697e+02  5.10618942e+02  3.54766471e+02  2.06367529e+03]\n",
      " [-4.09585212e+02 -3.21169746e+01  4.13225596e+02  3.86361442e+03]\n",
      " [ 3.70962163e-01 -6.45998576e-02  9.26398366e-01  1.05769926e+01]]\n",
      "det rotation_2 = 0.9999999999999999\n",
      "[[-3.18859623e+02  4.44216282e+02  3.20745489e+02  4.69952348e+03]\n",
      " [-5.52336834e+02 -1.77080640e+02 -5.57979247e+01  5.53183156e+03]\n",
      " [-4.50603040e-01 -1.85169023e-01  8.73309414e-01  1.56731179e+01]]\n",
      "det rotation_3 = 0.9999999999999999\n",
      "[[ 1.54859915e+02 -6.09317938e+02  8.14081749e+01  5.22599903e+03]\n",
      " [ 5.66922600e+02  3.10281350e+01  1.31083786e+02  6.24230476e+02]\n",
      " [ 2.24799463e-01 -3.83718847e-01  8.95670167e-01  1.24572852e+01]]\n",
      "det rotation_4 = 0.9999999999999998\n",
      "[[-1.71876742e+02  4.90407274e+02  3.63092722e+02  3.24136525e+03]\n",
      " [-5.53928857e+02  8.59206215e+01 -1.59145870e+02  3.97028895e+03]\n",
      " [-6.51013132e-01 -8.97951290e-02  7.53736517e-01  1.28122919e+01]]\n"
     ]
    }
   ],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "\n",
    "#the rvec is a vector representing the rotation axis, and its length encodes the angle in radians to rotate. \n",
    "#the Rodrigues method turns such a rotation vector into a 3x3 matrix.\n",
    "\n",
    "# in total we have 11 pictures the value of ret ~0.1 so we have a good calibration\n",
    "\n",
    "# To find the rotation matrix for each picture we simply applies the rodriguez formula seen in TD2.\n",
    "\n",
    "# once we have the rotation matrix of ONE rvecs vector(because rvecs is a vector of rotations vectors, for each of our\n",
    "# 11 patenrs). We use the rodriguez formula to find the rotation matrix, and once we have it we add the translation\n",
    "# vector (in tvecs which represtents a vector of translation vectors for each pattern/picture), to create our \n",
    "# extrinsic matrix for one pattern. And we rpeate this procedure for each pattern\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "print(\"mtx == \",mtx)\n",
    "\n",
    "rotation_0,_ = cv2.Rodrigues(rvecs[0])\n",
    "print(\"det rotation_0 =\",np.linalg.det(rotation_0))\n",
    "M_ext_0 = np.array(np.hstack((rotation_0,tvecs[0])),dtype=float)\n",
    "M_camera_0 = np.dot(mtx, M_ext_0)\n",
    "print(M_camera_0)\n",
    "\n",
    "rotation_1,_= cv2.Rodrigues(rvecs[1])\n",
    "print(\"det rotation_1 =\",np.linalg.det(rotation_1))\n",
    "M_ext_1 = np.array(np.hstack((rotation_1,tvecs[1])),dtype=float)\n",
    "M_camera_1 =np.dot(mtx, M_ext_1)\n",
    "print(M_camera_1)\n",
    "\n",
    "rotation_2,_ = cv2.Rodrigues( rvecs[2])\n",
    "print(\"det rotation_2 =\",np.linalg.det(rotation_2))\n",
    "M_ext_2 = np.array(np.hstack((rotation_2,tvecs[2])),dtype=float)\n",
    "M_camera_2 = np.dot(mtx, M_ext_2)\n",
    "print(M_camera_2)\n",
    "\n",
    "rotation_3,_= cv2.Rodrigues(rvecs[3])\n",
    "print(\"det rotation_3 =\",np.linalg.det(rotation_3))\n",
    "M_ext_3 = np.array(np.hstack((rotation_3,tvecs[3])),dtype=float)\n",
    "M_camera_3 = np.dot(mtx, M_ext_3)\n",
    "print(M_camera_3)\n",
    "\n",
    "rotation_4,_ = cv2.Rodrigues(rvecs[4])\n",
    "print(\"det rotation_4 =\",np.linalg.det(rotation_4))\n",
    "M_ext_4 = np.array(np.hstack((rotation_4,tvecs[4])),dtype=float)\n",
    "M_camera_4 = np.dot(mtx, M_ext_4)\n",
    "print(M_camera_4)\n",
    "# ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesion 1 \n",
    "The Cell 2 returns camera's intrinsic matrix, distortion parameters and rotation and translation vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 \n",
    "The calibration method used is the simple intrinsic calibration, because, the object is rectangular with known width W and Height H (6*7) with a static dimension for each square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "The first three parameters are ret, mtx and dist.\n",
    "<li>ret is the rate of precision of the calibration (this value is between 0 and 1) if this value is close to 0 this will mean that we have a perfect calibration of our camera (in our case it’s around 0.1 so we can say that we have a good calibration). This is why they use 13 images in the tutorial. </li>\n",
    "<li>Mtx is referred to the intrinsic matrix.</li>\n",
    "<li>Dist is for distortion coefficients that aim to restore an image radial and tangential distortion. The radial distortion makes the straight line appear curved while the tangential distortion comes from the non-alignment of the camera’s lense and the imaging plan which makes some areas seem nearer.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "<li>rvecs = rotation vectors (here it is a vector of 11 x 3)</li>\n",
    "<li>tvecs = translation vectors (here it is a vector of 11 x 3)</li>\n",
    "\n",
    "The output vectors rvecs and tvecs are respectively the rotation and translation vectors as detailed above. \n",
    "The rotation matrix is what allows the imaging plane and the real one to be on the same plane while the translation matrix superimposes the centres of reality and camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "rvecs is the rotation vector, to transform it into R the rotation matrix we need to use the Rodriguez formula.\n",
    "Once we get the rotation matrix for the 1st image (pattern), we concaten this matrix with its translation vector. (here the code of cv2.findChessboardCorners(gray, (7,6),None) has found 11 rotation vector and 11 translation vector for all the 11/13 images).<br>\n",
    "The code in openCV to get the rotation matrix is cv2.Rodrigues(rvecs[0]) for the first pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera matrix refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('left/left12.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult1.png',dst)\n",
    "\n",
    "# 2\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult2.png',dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "By comparing the output images of Cell3 and the original image we can see that the images have now straight edges. \n",
    "Earlier, we explained how the distortion coefficients are computed and to what purpose it is done. So when we estimated homographies between overlapping images, we should have been working with undistorted images so that the edges look straight.\n",
    "To undistort an image we can use one of the two methods below :\n",
    "<ol>\n",
    "<li>The undistort() function from the cv2 python library allows us to do so. Then, we use “ roi ” that sets a region of interest from a given rectangle by cropping the image. Finally, we save this image by using the cv2 function imwrite().</li>\n",
    "<li>Mapping the distorted image by using the cv2 function initUndistortRectifyMap() then remapping it with the function cv2.remap() and finally saving the image by using the imwrite() function as explained before.</li> \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this cell computes the rate of error of finding corners and calibrating pattern. When this value approaches 0\n",
    "this will mean that there are no errors and the calibration was perfect. This implies that cv.findChessboardCorners(...) shall alwayes return true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.023686000375385673\n"
     ]
    }
   ],
   "source": [
    "tot_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    tot_error += error\n",
    "\n",
    "print(\"total error: \", tot_error/len(objpoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "This cell computes the rate of error of finding corners and calibrating patterns. When this value approaches 0 this will mean that there are no errors and the calibration is perfect. This implies that cv.findChessboardCorners(...) shall always return true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  B. Teapot on the checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from text file\n",
    "tp= np.loadtxt(\"teapot.txt\",usecols=range(3))\n",
    "# Number of points in the cloud\n",
    "n_points = np.shape(tp)\n",
    "# Transpose and add a fourth coordinate with unitary value \n",
    "# (homogeneous coordinates)\n",
    "tp = np.hstack((tp,np.ones((n_points[0],1),dtype=np.float))).T\n",
    "# Save it in a data frame\n",
    "df = pd.DataFrame({\"x\" : tp[0,:], \"y\" :tp[1,:], \"z\" : tp[2,:], \n",
    "                                                \"w\": tp[3,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y        z    w\n",
      "0     1.381370  0.000000  2.45469  1.0\n",
      "1     1.400000  0.000000  2.40000  1.0\n",
      "2     1.350740 -0.375926  2.40000  1.0\n",
      "3     1.332760 -0.370922  2.45469  1.0\n",
      "4     1.384260  0.000000  2.48750  1.0\n",
      "...        ...       ...      ...  ...\n",
      "1172  0.205180  0.120647  2.88333  1.0\n",
      "1173  0.268946  0.075078  3.12708  1.0\n",
      "1174  0.350254  0.097771  3.06667  1.0\n",
      "1175  0.313617  0.087529  2.98125  1.0\n",
      "1176  0.228728  0.063803  2.88333  1.0\n",
      "\n",
      "[1177 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_cameras = []\n",
    "\n",
    "for i in range(counter):\n",
    "    rotation,_ = cv2.Rodrigues(rvecs[i])\n",
    "    M_cameras.append(np.dot(mtx, np.array(np.hstack((rotation,tvecs[i])),dtype=float)))\n",
    "\n",
    "print(M_cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.20818148e+02, -6.11700780e+01,  4.70156932e+02,\n",
      "         7.10303538e+03],\n",
      "       [ 4.45519202e+01, -5.64957870e+02,  1.35590083e+02,\n",
      "         3.94155712e+03],\n",
      "       [ 2.71751068e-01, -1.63273781e-01,  9.48416063e-01,\n",
      "         1.48593055e+01]]), array([[ 1.23637697e+02,  5.10618942e+02,  3.54766471e+02,\n",
      "         2.06367529e+03],\n",
      "       [-4.09585212e+02, -3.21169746e+01,  4.13225596e+02,\n",
      "         3.86361442e+03],\n",
      "       [ 3.70962163e-01, -6.45998576e-02,  9.26398366e-01,\n",
      "         1.05769926e+01]]), array([[-3.18859623e+02,  4.44216282e+02,  3.20745489e+02,\n",
      "         4.69952348e+03],\n",
      "       [-5.52336834e+02, -1.77080640e+02, -5.57979247e+01,\n",
      "         5.53183156e+03],\n",
      "       [-4.50603040e-01, -1.85169023e-01,  8.73309414e-01,\n",
      "         1.56731179e+01]]), array([[ 1.54859915e+02, -6.09317938e+02,  8.14081749e+01,\n",
      "         5.22599903e+03],\n",
      "       [ 5.66922600e+02,  3.10281350e+01,  1.31083786e+02,\n",
      "         6.24230476e+02],\n",
      "       [ 2.24799463e-01, -3.83718847e-01,  8.95670167e-01,\n",
      "         1.24572852e+01]]), array([[-1.71876742e+02,  4.90407274e+02,  3.63092722e+02,\n",
      "         3.24136525e+03],\n",
      "       [-5.53928857e+02,  8.59206215e+01, -1.59145870e+02,\n",
      "         3.97028895e+03],\n",
      "       [-6.51013132e-01, -8.97951290e-02,  7.53736517e-01,\n",
      "         1.28122919e+01]]), array([[-4.13254335e+02,  2.76734772e+02,  3.93085174e+02,\n",
      "         5.00310149e+03],\n",
      "       [-1.14571156e+02, -4.25375296e+02,  3.81413486e+02,\n",
      "         3.77316735e+03],\n",
      "       [ 2.29999624e-01,  2.36811992e-01,  9.43938691e-01,\n",
      "         9.90005138e+00]]), array([[-4.37170377e+02,  4.49822859e+01,  4.56876229e+02,\n",
      "         5.25020216e+03],\n",
      "       [ 6.43291804e+01, -5.03989799e+02,  2.85312072e+02,\n",
      "         3.74027591e+03],\n",
      "       [ 2.38411490e-01,  1.14196333e-01,  9.64426855e-01,\n",
      "         1.09576295e+01]]), array([[ 5.54934424e+01,  5.07367970e+02,  3.75999275e+02,\n",
      "         2.65725821e+03],\n",
      "       [-3.52618664e+02, -1.33803715e+02,  4.44188679e+02,\n",
      "         3.65599956e+03],\n",
      "       [ 4.65828918e-01, -3.31036931e-02,  8.84255373e-01,\n",
      "         9.56289277e+00]]), array([[ 2.05146898e+01,  3.32091432e+02,  5.39603245e+02,\n",
      "         6.36217685e+03],\n",
      "       [-5.49084576e+02, -3.75492785e+01,  1.91423926e+02,\n",
      "         5.79178776e+03],\n",
      "       [-8.12330085e-02, -4.28632278e-01,  8.99819742e-01,\n",
      "         1.61205447e+01]]), array([[ 1.89099658e+02,  3.70659515e+02,  4.78257333e+02,\n",
      "         2.55654811e+03],\n",
      "       [-4.92747769e+02,  7.72784456e+01,  3.01288263e+02,\n",
      "         5.18840630e+03],\n",
      "       [ 5.37803617e-02, -3.24503236e-01,  9.44354448e-01,\n",
      "         1.67785903e+01]]), array([[ 2.39965860e+02,  4.14688118e+02,  4.15123337e+02,\n",
      "         2.25431905e+03],\n",
      "       [-4.14224135e+02,  2.18683205e+01,  4.09251856e+02,\n",
      "         3.88475584e+03],\n",
      "       [ 3.20306069e-01, -2.70564391e-01,  9.07854026e-01,\n",
      "         1.17283334e+01]])]\n",
      "xs =  [1.38137  1.4      1.35074  ... 0.350254 0.313617 0.228728]\n",
      "ys =  [ 0.        0.       -0.375926 ...  0.097771  0.087529  0.063803]\n",
      "zs =  [2.45469 2.4     2.4     ... 3.06667 2.98125 2.88333]\n",
      "xs =  [0.690685  0.7       0.67537   ... 0.175127  0.1568085 0.114364 ]\n",
      "ys =  [ 0.         0.        -0.187963  ...  0.0488855  0.0437645  0.0319015]\n",
      "zs =  [-1.227345 -1.2      -1.2      ... -1.533335 -1.490625 -1.441665]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# question 3\n",
    "tp2=np.vstack((df['x'],df['y'],df['z'],df['w']))\n",
    "\n",
    "xs = tp2[0]\n",
    "ys = tp2[1]\n",
    "zs = tp2[2]\n",
    "\n",
    "print(\"xs = \", xs)\n",
    "print(\"ys = \", ys)\n",
    "print(\"zs = \", zs)\n",
    "for i in range(len(xs)):\n",
    "    xs[i] *= 0.5\n",
    "\n",
    "for i in range (len(ys)):\n",
    "    ys[i] *= 0.5\n",
    "    \n",
    "for i in range(len(zs)):\n",
    "    zs[i] *= -0.5 \n",
    "    \n",
    "print(\"xs = \", xs)\n",
    "print(\"ys = \", ys)\n",
    "print(\"zs = \", zs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(counter):\n",
    "    u_sim=np.dot(M_cameras[i],tp2)\n",
    "    u_sim = u_sim/u_sim[2,:]\n",
    "    imgname = valide_images[i]\n",
    "    print(imgname)\n",
    "    img=mpimg.imread(imgname)\n",
    "    #plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.scatter(u_sim[0,:],u_sim[1,:],s=2)\n",
    "    #plt.show()\n",
    "    strfile=\"projections/\"+imgname[5:]\n",
    "    plt.savefig(strfile)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graph(num,i):\n",
    "    # Load point cloud from data frame\n",
    "    tp=np.vstack((df['x'],df['y'],df['z'],df['w']))\n",
    "    xs = tp[0]\n",
    "    ys = tp[1]\n",
    "    zs = tp[2]\n",
    "    for i in range(len(xs)):\n",
    "        xs[i] *= 0.5\n",
    "\n",
    "    for i in range (len(ys)):\n",
    "        ys[i] *= 0.5\n",
    "    \n",
    "    for i in range(len(zs)):\n",
    "        zs[i] *= -0.5 \n",
    "   \n",
    "    tp_r = np.dot(M_cameras[i],tp)\n",
    "    graph._offsets3d = (tp_r[0,:], tp_r[1,:], tp_r[2,:])\n",
    "    return graph"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
