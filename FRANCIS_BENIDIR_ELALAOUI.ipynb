{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "# This is a value for the termination criterion of the subpixel corner localizer\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the 3D point coordinates and loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you have 3D points for the checkerboard (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "# Here you load the image files\n",
    "images = glob.glob('left/left*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "print(len(images))\n",
    "counter = 0\n",
    "valide_images = []\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6),None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        counter+=1\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        img = cv2.drawChessboardCorners(img, (7,6), corners2,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "        valide_images.append(fname)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtx ==  [[534.07088364   0.         341.53407553]\n",
      " [  0.         534.11914595 232.9456526 ]\n",
      " [  0.           0.           1.        ]]\n",
      "det rotation_0 = 1.0000000000000004\n",
      "[[-4.20818148e+02 -6.11700780e+01  4.70156932e+02  7.10303538e+03]\n",
      " [ 4.45519202e+01 -5.64957870e+02  1.35590083e+02  3.94155712e+03]\n",
      " [ 2.71751068e-01 -1.63273781e-01  9.48416063e-01  1.48593055e+01]]\n",
      "det rotation_1 = 0.9999999999999999\n",
      "[[ 1.23637697e+02  5.10618942e+02  3.54766471e+02  2.06367529e+03]\n",
      " [-4.09585212e+02 -3.21169746e+01  4.13225596e+02  3.86361442e+03]\n",
      " [ 3.70962163e-01 -6.45998576e-02  9.26398366e-01  1.05769926e+01]]\n",
      "det rotation_2 = 0.9999999999999999\n",
      "[[-3.18859623e+02  4.44216282e+02  3.20745489e+02  4.69952348e+03]\n",
      " [-5.52336834e+02 -1.77080640e+02 -5.57979247e+01  5.53183156e+03]\n",
      " [-4.50603040e-01 -1.85169023e-01  8.73309414e-01  1.56731179e+01]]\n",
      "det rotation_3 = 0.9999999999999999\n",
      "[[ 1.54859915e+02 -6.09317938e+02  8.14081749e+01  5.22599903e+03]\n",
      " [ 5.66922600e+02  3.10281350e+01  1.31083786e+02  6.24230476e+02]\n",
      " [ 2.24799463e-01 -3.83718847e-01  8.95670167e-01  1.24572852e+01]]\n",
      "det rotation_4 = 0.9999999999999998\n",
      "[[-1.71876742e+02  4.90407274e+02  3.63092722e+02  3.24136525e+03]\n",
      " [-5.53928857e+02  8.59206215e+01 -1.59145870e+02  3.97028895e+03]\n",
      " [-6.51013132e-01 -8.97951290e-02  7.53736517e-01  1.28122919e+01]]\n"
     ]
    }
   ],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "\n",
    "#the rvec is a vector representing the rotation axis, and its length encodes the angle in radians to rotate. \n",
    "#the Rodrigues method turns such a rotation vector into a 3x3 matrix.\n",
    "\n",
    "# in total we have 11 pictures the value of ret ~0.1 so we have a good calibration\n",
    "\n",
    "# To find the rotation matrix for each picture we simply applies the rodriguez formula seen in TD2.\n",
    "\n",
    "# once we have the rotation matrix of ONE rvecs vector(because rvecs is a vector of rotations vectors, for each of our\n",
    "# 11 patenrs). We use the rodriguez formula to find the rotation matrix, and once we have it we add the translation\n",
    "# vector (in tvecs which represtents a vector of translation vectors for each pattern/picture), to create our \n",
    "# extrinsic matrix for one pattern. And we rpeate this procedure for each pattern\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "print(\"mtx == \",mtx)\n",
    "\n",
    "rotation_0,_ = cv2.Rodrigues(rvecs[0])\n",
    "print(\"det rotation_0 =\",np.linalg.det(rotation_0))\n",
    "M_ext_0 = np.array(np.hstack((rotation_0,tvecs[0])),dtype=float)\n",
    "M_camera_0 = np.dot(mtx, M_ext_0)\n",
    "print(M_camera_0)\n",
    "\n",
    "rotation_1,_= cv2.Rodrigues(rvecs[1])\n",
    "print(\"det rotation_1 =\",np.linalg.det(rotation_1))\n",
    "M_ext_1 = np.array(np.hstack((rotation_1,tvecs[1])),dtype=float)\n",
    "M_camera_1 =np.dot(mtx, M_ext_1)\n",
    "print(M_camera_1)\n",
    "\n",
    "rotation_2,_ = cv2.Rodrigues( rvecs[2])\n",
    "print(\"det rotation_2 =\",np.linalg.det(rotation_2))\n",
    "M_ext_2 = np.array(np.hstack((rotation_2,tvecs[2])),dtype=float)\n",
    "M_camera_2 = np.dot(mtx, M_ext_2)\n",
    "print(M_camera_2)\n",
    "\n",
    "rotation_3,_= cv2.Rodrigues(rvecs[3])\n",
    "print(\"det rotation_3 =\",np.linalg.det(rotation_3))\n",
    "M_ext_3 = np.array(np.hstack((rotation_3,tvecs[3])),dtype=float)\n",
    "M_camera_3 = np.dot(mtx, M_ext_3)\n",
    "print(M_camera_3)\n",
    "\n",
    "rotation_4,_ = cv2.Rodrigues(rvecs[4])\n",
    "print(\"det rotation_4 =\",np.linalg.det(rotation_4))\n",
    "M_ext_4 = np.array(np.hstack((rotation_4,tvecs[4])),dtype=float)\n",
    "M_camera_4 = np.dot(mtx, M_ext_4)\n",
    "print(M_camera_4)\n",
    "# ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera matrix refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('left/left12.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult1.png',dst)\n",
    "\n",
    "# 2\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult2.png',dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this cell computes the rate of error of finding corners and calibrating pattern. When this value approaches 0\n",
    "this will mean that there are no errors and the calibration was perfect. This implies that cv.findChessboardCorners(...) shall alwayes return true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.023686000375385673\n"
     ]
    }
   ],
   "source": [
    "tot_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    tot_error += error\n",
    "\n",
    "print(\"total error: \", tot_error/len(objpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from text file\n",
    "tp= np.loadtxt(\"teapot.txt\",usecols=range(3))\n",
    "# Number of points in the cloud\n",
    "n_points = np.shape(tp)\n",
    "# Transpose and add a fourth coordinate with unitary value \n",
    "# (homogeneous coordinates)\n",
    "tp = np.hstack((tp,np.ones((n_points[0],1),dtype=np.float))).T\n",
    "# Save it in a data frame\n",
    "df = pd.DataFrame({\"x\" : tp[0,:], \"y\" :tp[1,:], \"z\" : tp[2,:], \n",
    "                                                \"w\": tp[3,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y        z    w\n",
      "0     1.381370  0.000000  2.45469  1.0\n",
      "1     1.400000  0.000000  2.40000  1.0\n",
      "2     1.350740 -0.375926  2.40000  1.0\n",
      "3     1.332760 -0.370922  2.45469  1.0\n",
      "4     1.384260  0.000000  2.48750  1.0\n",
      "...        ...       ...      ...  ...\n",
      "1172  0.205180  0.120647  2.88333  1.0\n",
      "1173  0.268946  0.075078  3.12708  1.0\n",
      "1174  0.350254  0.097771  3.06667  1.0\n",
      "1175  0.313617  0.087529  2.98125  1.0\n",
      "1176  0.228728  0.063803  2.88333  1.0\n",
      "\n",
      "[1177 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_cameras = []\n",
    "def update_graph(num,i):\n",
    "    # Load point cloud from data frame\n",
    "    tp=np.vstack((df['x'],df['y'],df['z'],df['w']))\n",
    "    xs = tp[0]\n",
    "    ys = tp[1]\n",
    "    zs = tp[2]\n",
    "    for i in range(len(xs)):\n",
    "        xs[i] *= 0.5\n",
    "\n",
    "    for i in range (len(ys)):\n",
    "        ys[i] *= 0.5\n",
    "    \n",
    "    for i in range(len(zs)):\n",
    "        zs[i] *= -0.5 \n",
    "   \n",
    "    tp_r = np.dot(M_cameras[i],tp)\n",
    "    graph._offsets3d = (tp_r[0,:], tp_r[1,:], tp_r[2,:])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
